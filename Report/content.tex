\setlength{\headheight}{15pt}
\lhead{\textbf{ITCS-6150}}
\chead{\textbf{Group 7}}
\rhead{\textbf{Final Report}}

\vspace{-2pt}

\begin{center}
    \begin{Large}
        \noindent\textbf{A Survey on the Limitations of Text Summarization Models}
    \end{Large}
\end{center}

\vspace{-10pt}

% Two column display for Team Members and Models & Datasets
\begin{multicols}{2}

    \begin{center}
        \begin{large}
            \noindent\textbf{Team Members}
        \end{large}
    \end{center}
    % Table of group members and their ids
    % Correct column widths for a table
    % 2 columns, 2 rows, no header
    \begin{center}
        \begin{tabular}{|lc|}
            \hline
            \textbf{David Gary} & \href{mailto:dgary9@uncc.edu}{801325583} \\ \hline
            \textbf{Michael Smalenberger} & \href{mailto:msmalenb@uncc.edu}{800984973} \\ \hline
            \textbf{Matthew Seman} & \href{mailto:mseman1@uncc.edu}{801156143} \\ \hline
            \textbf{Ryan Marsh} & \href{mailto:rmarsh4@uncc.edu}{800552800} \\ \hline
        \end{tabular}
    \end{center}

    \begin{center}
        \begin{large}
            \noindent\textbf{Models}
        \end{large}
    \end{center}

    \begin{center}
        \begin{tabular}{|lc|}
            \hline
            \href{https://github.com/zihangdai/xlnet}{XLNet Model\cite{XLNet}} & \href{https://huggingface.co/t5-base}{T5 Model\cite{T5}} \\ \hline
            \href{https://huggingface.co/facebook/bart-large-cnn}{BART Model\cite{BART}} &  \href{https://huggingface.co/facebook/bart-large-xsum}{BART-X Model\cite{BART}} \\ \hline
            \href{https://huggingface.co/google/pegasus-large}{Pegasus Model\cite{Pegasus}} &  \href{https://huggingface.co/google/pegasus-xsum}{Pegasus-X Model\cite{PegasusX}} \\ \hline
        \end{tabular}
    \end{center}


    \begin{center}
        \begin{large}
            \noindent\textbf{Sentiment Analysis Datasets}
        \end{large}
    \end{center}

    \begin{center}
        \begin{tabular}{|c|}
            \hline
            \href{https://paperswithcode.com/dataset/reddit-tifu}{Reddit TIFU Dataset\cite{RedditTIFU}} \\ \hline
            \href{https://paperswithcode.com/dataset/multi-news}{Multi-News Dataset\cite{Multinews}} \\ \hline
            \href{https://paperswithcode.com/dataset/s2orc}{S2ORC Dataset\cite{S2ORC}} \\ \hline
        \end{tabular}
    \end{center}

    \begin{center}
        \begin{large}
            \noindent\textbf{Summarization Datasets}
        \end{large}
    \end{center}

    \begin{center}
        \begin{tabular}{|c|}
            \hline
            \href{https://huggingface.co/datasets/gigaword}{Gigaword Dataset\cite{Gigaword1,Gigaword2}} \\ \hline
            \href{https://huggingface.co/datasets/cnn_dailymail}{CNN/DailyMail Dataset\cite{CNNDM}} \\ \hline
            \href{https://huggingface.co/datasets/xsum}{XSum Dataset\cite{XSumDataset}} \\ \hline
        \end{tabular}
    \end{center}

\end{multicols}

\begin{large}
    \noindent\textbf{Introduction}
\end{large}

\vspace{5pt}

With the increase in the availability of data in many fields, the need for summarizing texts has become increasingly important.
Condensing large amounts of information into concise and consumable bits of information can have significant personal and business implications.
For example, helping readers parse through complex topics by reducing the information to its salient points can help individuals quickly apply new information and gain expertise.
Similarly, businesses have begun to use social media posts to gauge public sentiment toward cryptocurrencies in order to hedge their portfolios\cite{Crypto1, Crypto2}.
Wading through this enormous amount of information would not be possible without the ability to summarize posts and accurately gauge sentiment.

\vspace{5pt}

Artificial intelligence, and specifically Intelligent Systems (IS) using natural language processing (NLP), is increasingly used in order to accomplish this task. As progress continues to be made in developing and fine-tuning NLP applications for text summarization, there has become an increasing number of models available from which to choose.
These models are often created in order to accomplish a specific objective and are not intended to be highly effective in every scenario. Hence, when measuring the efficacy of different models, one may arrive at different conclusions.
While this does certainly not mean that one model is necessarily better than another, it is essential to understand what leads to these different outcomes.
Levels of efficacy when applied in different scenarios. 

\vspace{5pt}

When intelligent systems summarize text, they may arrive at different conclusions based on the model they implement.
For example, two methods of scoring are ROUGE\cite{Rouge} and Pyramid\cite{Pyramid}.
These two scoring systems produce different evaluations of the intelligent system.
In order to continue to make progress in this field, it is crucial to investigate what causes these evaluations to be different and why.


\vspace{5pt}

\begin{large}
    \noindent\textbf{Problem Statement}
\end{large}

Our system implements text analysis and summarization following the current standards of generalizability.
We make our platform available so that anyone can use it to summarize text or assess the tone of text either using several publicly available datasets implemented by our system or by the user loading a different dataset of their choice.
However, since the primary purpose of this project is to show the limitations of generalized text summarization models, the user should be aware that we do not strive to achieve perfect accuracy in summarization or sentiment analysis.
Instead, we highlight the differences of the models implemented, and therefore the majority of the remaining analysis and discussion will focus on these differences. 

\vspace{5pt}

\begin{large}
    \noindent\textbf{Literature Survey}
\end{large}

Next, we will build on the XLNet framework to produce a generalized text summarizer.
This will include a score report that shows how well the model performs according to the Pyramid and ROUGE schemes.

\vspace{5pt}

\begin{large}
    \noindent\textbf{Our System}
\end{large}

\vspace{5pt}

Something here.

\pagebreak
