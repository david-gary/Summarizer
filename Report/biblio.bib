@inproceedings{Transformers,
  author    = {Guan, Wang and Smetannikov, Ivan and Tianxing, Man},
  title     = {Survey on Automatic Text Summarization and Transformer Models Applicability},
  year      = {2020},
  isbn      = {9781450388054},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3437802.3437832},
  doi       = {10.1145/3437802.3437832},
  booktitle = {2020 International Conference on Control, Robotics and Intelligent System},
  pages     = {176–184},
  numpages  = {9},
  keywords  = {Automatic Text Summarization, Pre-trained language model, Natural Language Processing},
  location  = {Xiamen, China},
  series    = {CCRIS 2020}
}

@article{Pyramid,
  author     = {Nenkova, Ani and Passonneau, Rebecca and McKeown, Kathleen},
  title      = {The Pyramid Method: Incorporating Human Content Selection Variation in Summarization Evaluation},
  year       = {2007},
  issue_date = {May 2007},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {4},
  number     = {2},
  issn       = {1550-4875},
  url        = {https://doi.org/10.1145/1233912.1233913},
  doi        = {10.1145/1233912.1233913},
  abstract   = {Human variation in content selection in summarization has given rise to some fundamental research questions: How can one incorporate the observed variation in suitable evaluation measures? How can such measures reflect the fact that summaries conveying different content can be equally good and informative? In this article, we address these very questions by proposing a method for analysis of multiple human abstracts into semantic content units. Such analysis allows us not only to quantify human variation in content selection, but also to assign empirical importance weight to different content units. It serves as the basis for an evaluation method, the Pyramid Method, that incorporates the observed variation and is predictive of different equally informative summaries. We discuss the reliability of content unit annotation, the properties of Pyramid scores, and their correlation with other evaluation methods.},
  journal    = {ACM Trans. Speech Lang. Process.},
  month      = {may},
  pages      = {4–es},
  numpages   = {23},
  keywords   = {summarization, Evaluation, semantic analysis}
}

@inproceedings{Rouge,
  title     = {{ROUGE}: A Package for Automatic Evaluation of Summaries},
  author    = {Lin, Chin-Yew},
  booktitle = {Text Summarization Branches Out},
  month     = jul,
  year      = {2004},
  address   = {Barcelona, Spain},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W04-1013},
  pages     = {74--81}
}

@misc{PegasusX,
  doi       = {10.48550/ARXIV.2208.04347},
  url       = {https://arxiv.org/abs/2208.04347},
  author    = {Phang, Jason and Zhao, Yao and Liu, Peter J.},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Investigating Efficiently Extending Transformers for Long Input Summarization},
  publisher = {arXiv},
  year      = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{GPT2,
  title  = {Language Models are Unsupervised Multitask Learners},
  author = {Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year   = {2019}
}

@misc{Pegasus,
  doi       = {10.48550/ARXIV.1912.08777},
  url       = {https://arxiv.org/abs/1912.08777},
  author    = {Zhang, Jingqing and Zhao, Yao and Saleh, Mohammad and Liu, Peter J.},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{T5,
  doi       = {10.48550/ARXIV.1910.10683},
  url       = {https://arxiv.org/abs/1910.10683},
  author    = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
  keywords  = {Machine Learning (cs.LG), Computation and Language (cs.CL), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{BART,
  doi       = {10.48550/ARXIV.1910.13461},
  url       = {https://arxiv.org/abs/1910.13461},
  author    = {Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{XLNet,
  doi       = {10.48550/ARXIV.1906.08237},
  url       = {https://arxiv.org/abs/1906.08237},
  author    = {Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Ruslan and Le, Quoc V.},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {XLNet: Generalized Autoregressive Pretraining for Language Understanding},
  publisher = {arXiv},
  year      = {2019},
  copyright = {Creative Commons Attribution 4.0 International}
}
