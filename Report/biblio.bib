@inproceedings{Transformers,
  author    = {Guan, Wang and Smetannikov, Ivan and Tianxing, Man},
  title     = {Survey on Automatic Text Summarization and Transformer Models Applicability},
  year      = {2020},
  isbn      = {9781450388054},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3437802.3437832},
  doi       = {10.1145/3437802.3437832},
  booktitle = {2020 International Conference on Control, Robotics and Intelligent System},
  pages     = {176–184},
  numpages  = {9},
  keywords  = {Automatic Text Summarization, Pre-trained language model, Natural Language Processing},
  location  = {Xiamen, China},
  series    = {CCRIS 2020}
}

@article{Pyramid,
  author     = {Nenkova, Ani and Passonneau, Rebecca and McKeown, Kathleen},
  title      = {The Pyramid Method: Incorporating Human Content Selection Variation in Summarization Evaluation},
  year       = {2007},
  issue_date = {May 2007},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {4},
  number     = {2},
  issn       = {1550-4875},
  url        = {https://doi.org/10.1145/1233912.1233913},
  doi        = {10.1145/1233912.1233913},
  abstract   = {Human variation in content selection in summarization has given rise to some fundamental research questions: How can one incorporate the observed variation in suitable evaluation measures? How can such measures reflect the fact that summaries conveying different content can be equally good and informative? In this article, we address these very questions by proposing a method for analysis of multiple human abstracts into semantic content units. Such analysis allows us not only to quantify human variation in content selection, but also to assign empirical importance weight to different content units. It serves as the basis for an evaluation method, the Pyramid Method, that incorporates the observed variation and is predictive of different equally informative summaries. We discuss the reliability of content unit annotation, the properties of Pyramid scores, and their correlation with other evaluation methods.},
  journal    = {ACM Trans. Speech Lang. Process.},
  month      = {may},
  pages      = {4–es},
  numpages   = {23},
  keywords   = {summarization, Evaluation, semantic analysis}
}

@inproceedings{Rouge,
  title     = {{ROUGE}: A Package for Automatic Evaluation of Summaries},
  author    = {Lin, Chin-Yew},
  booktitle = {Text Summarization Branches Out},
  month     = jul,
  year      = {2004},
  address   = {Barcelona, Spain},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W04-1013},
  pages     = {74--81}
}

@misc{PegasusX,
  doi       = {10.48550/ARXIV.2208.04347},
  url       = {https://arxiv.org/abs/2208.04347},
  author    = {Phang, Jason and Zhao, Yao and Liu, Peter J.},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Investigating Efficiently Extending Transformers for Long Input Summarization},
  publisher = {arXiv},
  year      = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{GPT2,
  title  = {Language Models are Unsupervised Multitask Learners},
  author = {Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year   = {2019}
}

@misc{Pegasus,
  doi       = {10.48550/ARXIV.1912.08777},
  url       = {https://arxiv.org/abs/1912.08777},
  author    = {Zhang, Jingqing and Zhao, Yao and Saleh, Mohammad and Liu, Peter J.},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{T5,
  doi       = {10.48550/ARXIV.1910.10683},
  url       = {https://arxiv.org/abs/1910.10683},
  author    = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
  keywords  = {Machine Learning (cs.LG), Computation and Language (cs.CL), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{BART,
  doi       = {10.48550/ARXIV.1910.13461},
  url       = {https://arxiv.org/abs/1910.13461},
  author    = {Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{XLNet,
  doi       = {10.48550/ARXIV.1906.08237},
  url       = {https://arxiv.org/abs/1906.08237},
  author    = {Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Ruslan and Le, Quoc V.},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {XLNet: Generalized Autoregressive Pretraining for Language Understanding},
  publisher = {arXiv},
  year      = {2019},
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{CNNDM,
  author     = {Ramesh Nallapati and
                Bing Xiang and
                Bowen Zhou},
  title      = {Sequence-to-Sequence RNNs for Text Summarization},
  journal    = {CoRR},
  volume     = {abs/1602.06023},
  year       = {2016},
  url        = {http://arxiv.org/abs/1602.06023},
  eprinttype = {arXiv},
  eprint     = {1602.06023},
  timestamp  = {Mon, 13 Aug 2018 16:46:52 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/NallapatiXZ16.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{Multinews,
  doi       = {10.48550/ARXIV.1906.01749},
  url       = {https://arxiv.org/abs/1906.01749},
  author    = {Fabbri, Alexander R. and Li, Irene and She, Tianwei and Li, Suyi and Radev, Dragomir R.},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Multi-News: a Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{RedditTIFU,
  doi       = {10.48550/ARXIV.1811.00783},
  url       = {https://arxiv.org/abs/1811.00783},
  author    = {Kim, Byeongchang and Kim, Hyunwoo and Kim, Gunhee},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Abstractive Summarization of Reddit Posts with Multi-level Memory Networks},
  publisher = {arXiv},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{S2ORC,
  title     = {{S}2{ORC}: The Semantic Scholar Open Research Corpus},
  author    = {Lo, Kyle  and
               Wang, Lucy Lu  and
               Neumann, Mark  and
               Kinney, Rodney  and
               Weld, Daniel},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.acl-main.447},
  doi       = {10.18653/v1/2020.acl-main.447},
  pages     = {4969--4983},
  abstract  = {We introduce S2ORC, a large corpus of 81.1M English-language academic papers spanning many academic disciplines. The corpus consists of rich metadata, paper abstracts, resolved bibliographic references, as well as structured full text for 8.1M open access papers. Full text is annotated with automatically-detected inline mentions of citations, figures, and tables, each linked to their corresponding paper objects. In S2ORC, we aggregate papers from hundreds of academic publishers and digital archives into a unified source, and create the largest publicly-available collection of machine-readable academic text to date. We hope this resource will facilitate research and development of tools and tasks for text mining over academic text.}
}

@misc{XSumDataset,
  doi       = {10.48550/ARXIV.1808.08745},
  url       = {https://arxiv.org/abs/1808.08745},
  author    = {Narayan, Shashi and Cohen, Shay B. and Lapata, Mirella},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Don't Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization},
  publisher = {arXiv},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Gigaword1,
  title   = {English gigaword},
  author  = {Graff, David and Kong, Junbo and Chen, Ke and Maeda, Kazuaki},
  journal = {Linguistic Data Consortium, Philadelphia},
  volume  = {4},
  number  = {1},
  pages   = {34},
  year    = {2003}
}

@article{Gigaword2,
  title     = {A Neural Attention Model for Abstractive Sentence Summarization},
  url       = {http://dx.doi.org/10.18653/v1/D15-1044},
  doi       = {10.18653/v1/d15-1044},
  journal   = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
  publisher = {Association for Computational Linguistics},
  author    = {Rush, Alexander M. and Chopra, Sumit and Weston, Jason},
  year      = {2015}
}

@misc{Crypto1,
  title     = {Algorithmic Trading of Cryptocurrency Based on Twitter Sentiment Analysis},
  author    = {Stuart G. Colianni and Stephanie M. Rosales and Michael Signorotti},
  year      = {2015},
  publisher = {IEEE}
}

@article{Crypto2,
  author  = {Kim, Young Bin and Kim, Jun and Kim, Wook and Im, Jaeho and Kim, TaeHyeong and Kang, Shin and Kim, Chang-Hun},
  year    = {2016},
  month   = {08},
  pages   = {e0161197},
  title   = {Predicting Fluctuations in Cryptocurrency Transactions Based on User Comments and Replies},
  volume  = {11},
  journal = {PLOS ONE},
  doi     = {10.1371/journal.pone.0161197}
}