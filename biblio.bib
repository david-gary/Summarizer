@inproceedings{Transformers,
  author    = {Guan, Wang and Smetannikov, Ivan and Tianxing, Man},
  title     = {Survey on Automatic Text Summarization and Transformer Models Applicability},
  year      = {2020},
  isbn      = {9781450388054},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3437802.3437832},
  doi       = {10.1145/3437802.3437832},
  booktitle = {2020 International Conference on Control, Robotics and Intelligent System},
  pages     = {176â€“184},
  numpages  = {9},
  keywords  = {Automatic Text Summarization, Pre-trained language model, Natural Language Processing},
  location  = {Xiamen, China},
  series    = {CCRIS 2020}
}

@misc{MultiNewsDataset,
  title         = {Multi-News: a Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model},
  author        = {Alexander R. Fabbri and Irene Li and Tianwei She and Suyi Li and Dragomir R. Radev},
  year          = {2019},
  eprint        = {1906.01749},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{XLNetSentiment,
  doi       = {10.48550/ARXIV.1906.08237},
  url       = {https://arxiv.org/abs/1906.08237},
  author    = {Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Ruslan and Le, Quoc V.},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {XLNet: Generalized Autoregressive Pretraining for Language Understanding},
  publisher = {arXiv},
  year      = {2019},
  copyright = {Creative Commons Attribution 4.0 International}
}
